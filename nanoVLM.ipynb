{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2de5dd1f",
      "metadata": {
        "id": "2de5dd1f"
      },
      "source": [
        "### Train a VLM in Google Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OCooV08mNANR",
      "metadata": {
        "id": "OCooV08mNANR"
      },
      "source": [
        "### Clone the repository if you don't have it already"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ooQMjmrMLn-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQMjmrMLn-4",
        "outputId": "873fbd28-d6dc-465f-9518-b1a624fec869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoVLM'...\n",
            "remote: Enumerating objects: 993, done.\u001b[K\n",
            "remote: Counting objects: 100% (606/606), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 993 (delta 501), reused 411 (delta 382), pack-reused 387 (from 2)\u001b[K\n",
            "Receiving objects: 100% (993/993), 13.37 MiB | 6.17 MiB/s, done.\n",
            "Resolving deltas: 100% (648/648), done.\n",
            "/content/nanoVLM\n",
            "assets\t\t\tdata\t\t models\t\ttests\n",
            "benchmark-inference.py\tgenerate.py\t nanoVLM.ipynb\ttrain.py\n",
            "benchmark_suite.py\tmeasure_vram.py  README.md\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('nanoVLM'):\n",
        "    !git clone https://github.com/huggingface/nanoVLM.git\n",
        "%cd nanoVLM/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mMhc9OCENup5",
      "metadata": {
        "id": "mMhc9OCENup5"
      },
      "source": [
        "### Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bcw8qQqoOSR7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcw8qQqoOSR7",
        "outputId": "be712275-8b00-4419-e5bf-0fc8e6c35b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# If you get an \"Error\" from pip's dependency resolver but the cell complets fine, this is not an issue, you can continue :)\n",
        "!pip -q install torch\n",
        "!pip -q install gcsfs\n",
        "!pip -q install datasets==3.5.0\n",
        "!pip -q install tqdm\n",
        "!pip -q install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "54bc8463",
      "metadata": {
        "id": "54bc8463",
        "outputId": "ca50d09b-e093-4c9d-e0e3-1fd97ae16039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "24b21e7aa7eb48fd89719749ce82613a",
            "0eae5260c50a44589c2081580c1de156",
            "dc019c315d8c42a1be5166bcd7a6080e",
            "8e865469a4e64808b05034d2d7c4eca1",
            "764e731419d746d199241dd77519af42",
            "fcb9446319744bd0b6d1a6b272c96e4c",
            "354b50e0c8f04b1b8b8e2b9f33ae213d",
            "a2c8983398f14748a878172b42049a07",
            "5571dd5bddd2417f926442610da8577c",
            "4d5bb65186034b75a3e57b5c65f6ebc1",
            "fce27771f8db4a9f8a7217ae996478d1",
            "9537bb723079416494c890abf52b1c61",
            "767b1d7131824c679626d64b9e97a8c1",
            "73313c89403e49ff9941441840f7d608",
            "21b06094645a420291d42bab35abd1d6",
            "98f5dc9997a34f91b03160f3ce40b3b8",
            "d18af8d831654a928bd48d6dbb104159",
            "debc72b056a8486fba9a3671315af97a",
            "cc55e790e2b14c50b8856faec4b90fbf",
            "6e517d46bf994634bd3ff473bcbfcb6b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24b21e7aa7eb48fd89719749ce82613a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Let's authentificate with the Hugging Face Hub so you can push your model\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e8dc5ba",
      "metadata": {
        "id": "5e8dc5ba"
      },
      "outputs": [],
      "source": [
        "# Decide on the name of your model here!\n",
        "# You will need your HF user name and the name you want to give to it\n",
        "# For me, this would be \"lusxvr/nanoVLM\"\n",
        "hf_model_name = \"Hemant$52/nanoVLM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "OTsl1jZrMeaJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsl1jZrMeaJ",
        "outputId": "f24b86a3-ebe8-4b6f-bb30-95b256846b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# nanoVLM Imports (please check out the implementations in detail, that's where all the interessting stuff is!)\n",
        "from data.collators import VQACollator, MMStarCollator\n",
        "from data.datasets import MMStarDataset, VQADataset\n",
        "from data.processors import get_image_processor, get_tokenizer\n",
        "from models.vision_language_model import VisionLanguageModel\n",
        "import models.utils as utils\n",
        "\n",
        "# Libraries\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass, field\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "#Otherwise, the tokenizer will through a warning\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# To reload the modules if you change something in the code\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Vzo03IzN3Zf",
      "metadata": {
        "id": "4Vzo03IzN3Zf"
      },
      "source": [
        "### Get the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3Zzn2FI2N7Aj",
      "metadata": {
        "id": "3Zzn2FI2N7Aj"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_cfg, vlm_cfg):\n",
        "    # Create datasets\n",
        "    image_processor = get_image_processor(vlm_cfg.vit_img_size)\n",
        "    tokenizer = get_tokenizer(vlm_cfg.lm_tokenizer, vlm_cfg.vlm_extra_tokens)\n",
        "\n",
        "    # Load and combine all training datasets\n",
        "    combined_train_data = []\n",
        "    for dataset_name in train_cfg.train_dataset_name:\n",
        "        train_ds = load_dataset(train_cfg.train_dataset_path, dataset_name)\n",
        "        combined_train_data.append(train_ds['train'])\n",
        "    train_ds = concatenate_datasets(combined_train_data)\n",
        "\n",
        "    test_ds = load_dataset(train_cfg.test_dataset_path)\n",
        "    train_ds = train_ds.shuffle(seed=0) # Shuffle the training dataset, so train and val get equal contributions from all concatinated datasets\n",
        "\n",
        "    # Apply cutoff if specified\n",
        "    if train_cfg.data_cutoff_idx is None:\n",
        "        total_samples = len(train_ds)  # Use the entire dataset\n",
        "    else:\n",
        "        total_samples = min(len(train_ds), train_cfg.data_cutoff_idx)\n",
        "\n",
        "    val_size = int(total_samples * train_cfg.val_ratio)\n",
        "    train_size = total_samples - val_size\n",
        "\n",
        "    train_dataset = VQADataset(train_ds.select(range(train_size)), tokenizer, image_processor)\n",
        "    val_dataset = VQADataset(train_ds.select(range(train_size, total_samples)), tokenizer, image_processor)\n",
        "    test_dataset = MMStarDataset(test_ds['val'], tokenizer, image_processor)\n",
        "\n",
        "    # Create collators\n",
        "    vqa_collator = VQACollator(tokenizer, vlm_cfg.lm_max_length, vlm_cfg.mp_image_token_length)\n",
        "    mmstar_collator = MMStarCollator(tokenizer, vlm_cfg.mp_image_token_length)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=vqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=vqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=train_cfg.mmstar_batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=mmstar_collator,\n",
        "        pin_memory=True,\n",
        "        )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D7NIuEDuOuuJ",
      "metadata": {
        "id": "D7NIuEDuOuuJ"
      },
      "source": [
        "### Prepare the testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9fnh6wOlOzat",
      "metadata": {
        "id": "9fnh6wOlOzat"
      },
      "outputs": [],
      "source": [
        "def test_mmstar(model, tokenizer, test_loader, device):\n",
        "    # Go through MMStar and count how many answers we get right\n",
        "    model.eval()\n",
        "    total_examples = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            image = batch['images'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            correct_answer = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            gen = model.generate(input_ids, image, attention_mask, greedy=True)\n",
        "            model_output = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "\n",
        "            is_correct = utils.check_multiple_choice_with_regex(model_output, correct_answer)\n",
        "\n",
        "            total_examples += len(is_correct)\n",
        "            if is_correct:\n",
        "                correct_predictions += sum(is_correct)\n",
        "\n",
        "    accuracy = correct_predictions / total_examples if total_examples > 0 else 0\n",
        "    model.train()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_F8u3MJ6PAfd",
      "metadata": {
        "id": "_F8u3MJ6PAfd"
      },
      "source": [
        "### Prepare the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "KxOtMU5zPD-4",
      "metadata": {
        "id": "KxOtMU5zPD-4"
      },
      "outputs": [],
      "source": [
        "def get_lr(it, max_lr, max_steps):\n",
        "    min_lr = max_lr * 0.1\n",
        "    warmup_steps = max_steps * 0.03\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it+1) / warmup_steps\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "def train(train_cfg, vlm_cfg):\n",
        "    train_loader, val_loader, test_loader = get_dataloaders(train_cfg, vlm_cfg)\n",
        "    tokenizer = get_tokenizer(vlm_cfg.lm_tokenizer, vlm_cfg.vlm_extra_tokens)\n",
        "\n",
        "    # Initialize model\n",
        "    if train_cfg.resume_from_vlm_checkpoint:\n",
        "        model = VisionLanguageModel.from_pretrained(vlm_cfg.vlm_checkpoint_path)\n",
        "    else:\n",
        "        model = VisionLanguageModel(vlm_cfg)\n",
        "\n",
        "    print(f\"nanoVLM initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "    print(f\"Training summary: {len(train_loader.dataset)} samples, {len(train_loader)} batches/epoch, batch size {train_cfg.batch_size}\")\n",
        "\n",
        "    # Define optimizer groups\n",
        "    param_groups = [{'params': model.MP.parameters(), 'lr': train_cfg.lr_mp},\n",
        "                    {'params': list(model.decoder.parameters()) + list(model.vision_encoder.parameters()), 'lr': train_cfg.lr_backbones}]\n",
        "    optimizer = optim.AdamW(param_groups)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    if train_cfg.compile:\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    epoch_times = []\n",
        "    batch_losses = []\n",
        "    val_losses = []\n",
        "    val_plot_steps = []\n",
        "    best_accuracy = 0\n",
        "    global_step = 0\n",
        "    for epoch in range(train_cfg.epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        total_tokens_processed = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "            images = batch[\"image\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16): # Mixed precision training\n",
        "                _, loss = model(input_ids, images, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            adj_lr_mp = get_lr(global_step, train_cfg.lr_mp, len(train_loader) * train_cfg.epochs)\n",
        "            adj_lr_backbones = get_lr(global_step, train_cfg.lr_backbones, len(train_loader) * train_cfg.epochs)\n",
        "            optimizer.param_groups[0]['lr'] = adj_lr_mp\n",
        "            optimizer.param_groups[1]['lr'] = adj_lr_backbones\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "            batch_losses.append(batch_loss)\n",
        "\n",
        "            num_tokens = torch.sum(attention_mask).item() # Sum of attention mask gives number of tokens\n",
        "            num_tokens += images.shape[0] * ((images.shape[2] / vlm_cfg.vit_patch_size) ** 2) / (vlm_cfg.mp_pixel_shuffle_factor ** 2) # Add image tokens = batch_size * (((img_size / patch_size) ** 2) / (pixel_shuffle_factor ** 2))\n",
        "            total_tokens_processed += num_tokens\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_duration = batch_end_time - batch_start_time\n",
        "            tokens_per_second = num_tokens / batch_duration\n",
        "\n",
        "            if global_step % 5 == 0:\n",
        "                model.eval()\n",
        "                torch.cuda.empty_cache()  # Clear GPU memory\n",
        "                with torch.no_grad():\n",
        "                    total_val_loss = 0\n",
        "                    for batch in val_loader:\n",
        "                        images = batch[\"image\"].to(device)\n",
        "                        input_ids = batch[\"input_ids\"].to(device)\n",
        "                        labels = batch[\"labels\"].to(device)\n",
        "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "                        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                            _, loss = model(input_ids, images, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "                        total_val_loss += loss.item()\n",
        "                    avg_val_loss = total_val_loss / len(val_loader)\n",
        "                    val_losses.append(avg_val_loss)\n",
        "                    val_plot_steps.append(global_step)\n",
        "                epoch_accuracy = 0\n",
        "                if train_cfg.eval_in_epochs:\n",
        "                    epoch_accuracy = test_mmstar(model, tokenizer, test_loader, device)\n",
        "                    if epoch_accuracy > best_accuracy:\n",
        "                      best_accuracy = epoch_accuracy\n",
        "                      model.save_pretrained(save_directory=vlm_cfg.vlm_checkpoint_path)\n",
        "                    print(f\"\\nStep: {global_step}, Loss: {batch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Tokens/s: {tokens_per_second:.2f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "                model.train()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        epoch_times.append(epoch_duration)\n",
        "\n",
        "        epoch_tokens_per_second = total_tokens_processed / epoch_duration\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{train_cfg.epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Time: {epoch_duration:.2f}s | T/s: {epoch_tokens_per_second:.2f}\")\n",
        "\n",
        "    # Summary Statistics\n",
        "    if not train_cfg.eval_in_epochs:\n",
        "      model.save_pretrained(save_directory=vlm_cfg.vlm_checkpoint_path)\n",
        "      model.push_to_hub(hf_model_name)\n",
        "\n",
        "\n",
        "    avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
        "    total_training_time = sum(epoch_times)\n",
        "    total_samples_processed = len(train_loader.dataset) * train_cfg.epochs\n",
        "    avg_time_per_sample = total_training_time / total_samples_processed\n",
        "    print(f\"Average time per epoch: {avg_epoch_time:.2f}s\")\n",
        "    print(f\"Average time per sample: {avg_time_per_sample:.4f}s\")\n",
        "\n",
        "    plt.plot(batch_losses, label='Train Loss')\n",
        "    plt.plot(val_plot_steps, val_losses, label='Val Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # With this code you can test the accuracy of the model on the MMStar dataset\n",
        "    # But if you only train with few samples, the accuracy will be very low\n",
        "    # print(\"Testing MMStar Accuracy:\")\n",
        "    # accuracy = test_mmstar(model, tokenizer, test_loader, device)\n",
        "    # print(f\"MMStar Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4HmsEPNQZbh",
      "metadata": {
        "id": "d4HmsEPNQZbh"
      },
      "source": [
        "### Prepare the Configs\n",
        "Instead of using the config.py file in the repo (which was created to run on one H100), we will create our config here to play around with the parameters easier and adapt them to colabs capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h8FlqtizQdO-",
      "metadata": {
        "id": "h8FlqtizQdO-"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class VLMConfig:\n",
        "    vit_hidden_dim: int = 768\n",
        "    vit_inter_dim: int = 4 * vit_hidden_dim\n",
        "    vit_patch_size: int = 16\n",
        "    vit_img_size: int = 224\n",
        "    vit_n_heads: int = 12\n",
        "    vit_dropout: float = 0.0\n",
        "    vit_n_blocks: int = 12\n",
        "    vit_ln_eps: float = 1e-6\n",
        "    vit_cls_flag: bool = False\n",
        "    vit_model_type: str = 'google/siglip-base-patch16-224'\n",
        "\n",
        "    lm_hidden_dim: int = 576\n",
        "    lm_inter_dim: int = 1536\n",
        "    lm_rms_eps: float = 1e-5\n",
        "    lm_re_base: int = 100000\n",
        "    lm_max_position_embeddings: int = 8192\n",
        "    lm_base_vocab_size: int = 49152\n",
        "    extra_token_amount: int = 1  # Number of extra tokens for the VLM (image start, image end, image token)\n",
        "    lm_vocab_size: int = lm_base_vocab_size + extra_token_amount # Not a great way to do this, but it works for now (vlm_extra_tokens cannot be a dict, since this is mutable, and a Field has no len() function)\n",
        "    lm_n_heads: int = 9\n",
        "    lm_n_kv_heads: int = 3\n",
        "    lm_dropout: float = 0.0\n",
        "    lm_n_blocks: int = 30\n",
        "    lm_attn_scaling: float = 1.0\n",
        "    lm_eos_token_id: int = 0\n",
        "    lm_max_length: int = 128\n",
        "    lm_use_tokens: bool = False # Decide if the LM expects tokens or embeddings as input (if using as a backbone for the VLM, set to False)\n",
        "    lm_tie_weights: bool = True # Decide if you want to tie the LM Head weight to the token embedding weights\n",
        "    lm_model_type: str = 'HuggingFaceTB/SmolLM2-135M'\n",
        "    lm_tokenizer: str = 'HuggingFaceTB/cosmo2-tokenizer'\n",
        "\n",
        "    mp_pixel_shuffle_factor: int = 2\n",
        "    mp_image_token_length: int = 49\n",
        "\n",
        "    vlm_extra_tokens: dict[str, str] = field(default_factory=lambda: {\"image_token\": \"<|image|>\"})#, \"boi_token\": \"<|image_start|>\", \"eoi_token\": \"<|image_end|>\"})\n",
        "    vlm_load_backbone_weights: bool = True\n",
        "    vlm_checkpoint_path: str = 'checkpoints'\n",
        "    hf_repo_name: str = 'nanoVLM'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    lr_mp: float = 1e-3\n",
        "    lr_backbones: float = 5e-5\n",
        "    val_ratio: float = 0.2\n",
        "    compile: bool = False\n",
        "    data_cutoff_idx: int = 1024 # Let's only use a small subset of the data at first, otherwise it takes very long to see anything :D\n",
        "    batch_size: int = 12\n",
        "    mmstar_batch_size: int = 12\n",
        "    epochs: int = 5\n",
        "    eval_in_epochs: bool = False # Deactivating this in colab, because it would evaluate 1500 samples of MMStar every time otherwise\n",
        "    resume_from_vlm_checkpoint: bool = False # Indicate if the training should be resumed from a checkpoint of the whole VLM or you want to start from scratch\n",
        "    train_dataset_path: str = 'HuggingFaceM4/the_cauldron'\n",
        "    train_dataset_name: tuple[str, ...] = (\"cocoqa\", \"clevr\") #All options; (\"ai2d\", \"aokvqa\", \"chart2text\", \"chartqa\", \"clevr\", \"cocoqa\", \"datikz\", \"diagram_image_to_text\", \"docvqa\", \"dvqa\", \"figureqa\", \"finqa\", \"geomverse\", \"hateful_memes\", \"hitab\", \"iam\", \"iconqa\", \"infographic_vqa\", \"intergps\", \"localized_narratives\", \"mapqa\", \"multihiertt\", \"ocrvqa\", \"plotqa\", \"raven\", \"rendered_text\", \"robut_sqa\", \"robut_wikisql\", \"robut_wtq\", \"scienceqa\", \"screen2words\", \"st_vqa\", \"tabmwp\", \"tallyqa\", \"tat_qa\", \"textcaps\", \"textvqa\", \"tqa\", \"vistext\", \"visual7w\", \"visualmrc\", \"vqarad\", \"vqav2\", \"vsr\", \"websight\") # \"clevr_math\", \"okvqa\", \"spot_the_diff\", \"nlvr2\", \"mimic_cgd\",\n",
        "    test_dataset_path: str = \"Lin-Chen/MMStar\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KmFQwKGcSLr_",
      "metadata": {
        "id": "KmFQwKGcSLr_"
      },
      "source": [
        "### Lets run the training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9MlFpXQFSNdx",
      "metadata": {
        "id": "9MlFpXQFSNdx"
      },
      "outputs": [],
      "source": [
        "vlm_cfg = VLMConfig()\n",
        "train_cfg = TrainConfig()\n",
        "train(train_cfg, vlm_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d938dd",
      "metadata": {
        "id": "78d938dd"
      },
      "source": [
        "As you can see the model trains, so feel free to play around with the architecture or data! Let us know what you build with it!\n",
        "\n",
        "PS: If you want to test the model, check out generate.py to see how to do inference with it"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24b21e7aa7eb48fd89719749ce82613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_354b50e0c8f04b1b8b8e2b9f33ae213d"
          }
        },
        "0eae5260c50a44589c2081580c1de156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c8983398f14748a878172b42049a07",
            "placeholder": "​",
            "style": "IPY_MODEL_5571dd5bddd2417f926442610da8577c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "dc019c315d8c42a1be5166bcd7a6080e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4d5bb65186034b75a3e57b5c65f6ebc1",
            "placeholder": "​",
            "style": "IPY_MODEL_fce27771f8db4a9f8a7217ae996478d1",
            "value": ""
          }
        },
        "8e865469a4e64808b05034d2d7c4eca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9537bb723079416494c890abf52b1c61",
            "style": "IPY_MODEL_767b1d7131824c679626d64b9e97a8c1",
            "value": true
          }
        },
        "764e731419d746d199241dd77519af42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_73313c89403e49ff9941441840f7d608",
            "style": "IPY_MODEL_21b06094645a420291d42bab35abd1d6",
            "tooltip": ""
          }
        },
        "fcb9446319744bd0b6d1a6b272c96e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f5dc9997a34f91b03160f3ce40b3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_d18af8d831654a928bd48d6dbb104159",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "354b50e0c8f04b1b8b8e2b9f33ae213d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a2c8983398f14748a878172b42049a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5571dd5bddd2417f926442610da8577c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5bb65186034b75a3e57b5c65f6ebc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce27771f8db4a9f8a7217ae996478d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9537bb723079416494c890abf52b1c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767b1d7131824c679626d64b9e97a8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73313c89403e49ff9941441840f7d608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b06094645a420291d42bab35abd1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "98f5dc9997a34f91b03160f3ce40b3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18af8d831654a928bd48d6dbb104159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "debc72b056a8486fba9a3671315af97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc55e790e2b14c50b8856faec4b90fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_6e517d46bf994634bd3ff473bcbfcb6b",
            "value": "Connecting..."
          }
        },
        "cc55e790e2b14c50b8856faec4b90fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e517d46bf994634bd3ff473bcbfcb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}